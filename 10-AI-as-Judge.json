{
  "name": "AI as Judge - Evaluation System",
  "nodes": [
    {
      "parameters": {
        "httpMethod": "POST",
        "path": "ai-as-judge-evaluate",
        "options": {}
      },
      "type": "n8n-nodes-base.webhook",
      "typeVersion": 1.1,
      "position": [400, 300],
      "id": "webhook-trigger",
      "name": "Webhook - Receive Evaluation Request",
      "webhookId": "ai-as-judge-eval"
    },
    {
      "parameters": {
        "assignments": {
          "assignments": [
            {
              "id": "agent-id",
              "name": "agent_id",
              "value": "={{ $json.body.agent_id }}",
              "type": "string"
            },
            {
              "id": "conversations",
              "name": "conversations",
              "value": "={{ $json.body.conversations }}",
              "type": "array"
            },
            {
              "id": "evaluation-mode",
              "name": "evaluation_mode",
              "value": "={{ $json.body.evaluation_mode || 'standard' }}",
              "type": "string"
            }
          ]
        },
        "options": {}
      },
      "type": "n8n-nodes-base.set",
      "typeVersion": 3.4,
      "position": [640, 300],
      "id": "extract-payload",
      "name": "Extract Request Payload"
    },
    {
      "parameters": {
        "conditions": {
          "options": {
            "caseSensitive": true,
            "leftValue": "",
            "typeValidation": "strict",
            "version": 2
          },
          "conditions": [
            {
              "id": "has-agent-id",
              "leftValue": "={{ $json.agent_id }}",
              "rightValue": "",
              "operator": {
                "type": "string",
                "operation": "exists",
                "singleValue": true
              }
            },
            {
              "id": "has-conversations",
              "leftValue": "={{ $json.conversations.length > 0 }}",
              "rightValue": true,
              "operator": {
                "type": "boolean",
                "operation": "equals"
              }
            }
          ],
          "combinator": "and"
        },
        "options": {}
      },
      "type": "n8n-nodes-base.if",
      "typeVersion": 2.2,
      "position": [880, 300],
      "id": "validate-input",
      "name": "Validate Input?"
    },
    {
      "parameters": {
        "respondWith": "json",
        "responseBody": "={{ { error: 'Missing required fields: agent_id and conversations array', status: 400 } }}",
        "options": {}
      },
      "type": "n8n-nodes-base.respondToWebhook",
      "typeVersion": 1.1,
      "position": [880, 500],
      "id": "respond-error",
      "name": "Respond - Error"
    },
    {
      "parameters": {
        "operation": "executeQuery",
        "query": "=SELECT \n  av.id,\n  av.agent_name,\n  av.system_prompt,\n  av.compliance_rules,\n  av.personality_config,\n  av.business_config,\n  av.location_id,\n  c.nome as cliente_nome\nFROM agent_versions av\nJOIN clients c ON av.client_id = c.id\nWHERE av.id = '{{ $json.agent_id }}'\n  AND av.is_active = true\nLIMIT 1",
        "options": {}
      },
      "type": "n8n-nodes-base.postgres",
      "typeVersion": 2.5,
      "position": [1120, 200],
      "id": "fetch-agent-prompt",
      "name": "Fetch Current Agent Prompt",
      "alwaysOutputData": false,
      "credentials": {
        "postgres": {
          "id": "w2mBaRwhZ3tM4FUw",
          "name": "Postgres Marcos Daniels."
        }
      }
    },
    {
      "parameters": {
        "conditions": {
          "options": {
            "caseSensitive": true,
            "leftValue": "",
            "typeValidation": "strict",
            "version": 2
          },
          "conditions": [
            {
              "id": "agent-found",
              "leftValue": "={{ $json.id }}",
              "rightValue": "",
              "operator": {
                "type": "string",
                "operation": "exists",
                "singleValue": true
              }
            }
          ],
          "combinator": "and"
        },
        "options": {}
      },
      "type": "n8n-nodes-base.if",
      "typeVersion": 2.2,
      "position": [1360, 200],
      "id": "agent-exists",
      "name": "Agent Exists?"
    },
    {
      "parameters": {
        "respondWith": "json",
        "responseBody": "={{ { error: 'Agent not found or inactive', status: 404 } }}",
        "options": {}
      },
      "type": "n8n-nodes-base.respondToWebhook",
      "typeVersion": 1.1,
      "position": [1360, 400],
      "id": "respond-not-found",
      "name": "Respond - Agent Not Found"
    },
    {
      "parameters": {
        "jsCode": "// Preparar contexto de avaliacao com rubrica\nconst agentData = $('Fetch Current Agent Prompt').first().json;\nconst requestData = $('Extract Request Payload').first().json;\n\n// Parse agent configs\nfunction safeJsonParse(val, fallback = {}) {\n  if (typeof val === 'string') {\n    try { return JSON.parse(val); } catch { return fallback; }\n  }\n  return val || fallback;\n}\n\nconst systemPrompt = agentData.system_prompt || '';\nconst complianceRules = safeJsonParse(agentData.compliance_rules);\nconst personalityConfig = safeJsonParse(agentData.personality_config);\nconst businessConfig = safeJsonParse(agentData.business_config);\nconst conversations = requestData.conversations || [];\n\n// RUBRICA DE AVALIACAO (5 criterios ponderados)\nconst rubrica = {\n  completeness: {\n    weight: 0.20,\n    description: \"Did the agent fully address the user's request?\",\n    scale: {\n      5: \"Fully addressed all aspects of the request comprehensively\",\n      4: \"Addressed most aspects, minor elements missing\",\n      3: \"Addressed main points but missed important details\",\n      2: \"Partially addressed, significant gaps\",\n      1: \"Barely addressed or completely missed the request\"\n    }\n  },\n  depth: {\n    weight: 0.25,\n    description: \"Was the response thorough and insightful?\",\n    scale: {\n      5: \"Exceptional depth with valuable insights and context\",\n      4: \"Good depth with relevant details and explanations\",\n      3: \"Adequate depth but could be more thorough\",\n      2: \"Surface-level, lacks necessary depth\",\n      1: \"Extremely shallow or generic\"\n    }\n  },\n  tone: {\n    weight: 0.15,\n    description: \"Was the tone appropriate for the context?\",\n    scale: {\n      5: \"Perfect tone matching context and user expectations\",\n      4: \"Good tone with minor inconsistencies\",\n      3: \"Acceptable but could be more aligned\",\n      2: \"Tone somewhat inappropriate or inconsistent\",\n      1: \"Tone completely inappropriate or off-putting\"\n    }\n  },\n  scope: {\n    weight: 0.20,\n    description: \"Did the agent stay on topic and relevant?\",\n    scale: {\n      5: \"Perfectly on-topic, all content relevant\",\n      4: \"Mostly on-topic with minimal tangents\",\n      3: \"Generally on-topic but some irrelevant content\",\n      2: \"Frequently off-topic or unfocused\",\n      1: \"Completely off-topic or irrelevant\"\n    }\n  },\n  missed_opportunities: {\n    weight: 0.20,\n    description: \"Did the agent miss chances to help or add value?\",\n    scale: {\n      5: \"Seized all opportunities, proactive and helpful\",\n      4: \"Caught most opportunities with minor misses\",\n      3: \"Caught some opportunities but missed clear ones\",\n      2: \"Missed several obvious opportunities\",\n      1: \"Completely missed all opportunities to add value\"\n    },\n    inverse: true // Lower score is better (fewer missed opportunities)\n  }\n};\n\n// Formatar conversas para avaliacao\nconst conversationsFormatted = conversations.map((conv, idx) => {\n  const messages = conv.messages || [];\n  const formatted = messages.map(msg => {\n    const role = msg.is_from_lead ? 'USER' : 'AGENT';\n    const timestamp = msg.timestamp || msg.created_at || '';\n    return `[${timestamp}] ${role}: ${msg.message_text || msg.text || ''}`;\n  }).join('\\n');\n  \n  return {\n    conversation_index: idx + 1,\n    conversation_id: conv.id || conv.conversation_id || `conv_${idx + 1}`,\n    formatted_messages: formatted,\n    message_count: messages.length,\n    result: conv.result || conv.resultado || 'unknown'\n  };\n});\n\n// Extrair expectativas do negocio\nconst expectedTone = personalityConfig.tom || personalityConfig.tone || 'professional';\nconst businessType = businessConfig.tipo_negocio || businessConfig.especialidade || 'general';\nconst prohibitions = complianceRules.proibicoes || complianceRules.prohibited_actions || [];\n\nreturn [{\n  json: {\n    agent: {\n      id: agentData.id,\n      name: agentData.agent_name,\n      client_name: agentData.cliente_nome,\n      location_id: agentData.location_id\n    },\n    system_prompt_snippet: systemPrompt.substring(0, 1000),\n    context: {\n      expected_tone: expectedTone,\n      business_type: businessType,\n      prohibitions: prohibitions\n    },\n    rubrica: rubrica,\n    conversations: conversationsFormatted,\n    total_conversations: conversationsFormatted.length,\n    evaluation_mode: requestData.evaluation_mode\n  }\n}];"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [1600, 100],
      "id": "prepare-evaluation",
      "name": "Prepare Evaluation Context + Rubric"
    },
    {
      "parameters": {
        "promptType": "define",
        "text": "=## CONVERSATIONS TO EVALUATE\n\n{{ $json.conversations.map((c, i) => `### Conversation ${c.conversation_index} (ID: ${c.conversation_id})\n**Messages:** ${c.message_count}\n**Result:** ${c.result}\n\n${c.formatted_messages}\n\n---`).join('\\n\\n') }}\n\n## AGENT CONTEXT\n\n**Agent Name:** {{ $json.agent.name }}\n**Client:** {{ $json.agent.client_name }}\n**Business Type:** {{ $json.context.business_type }}\n**Expected Tone:** {{ $json.context.expected_tone }}\n\n**System Prompt (First 1000 chars):**\n{{ $json.system_prompt_snippet }}\n\n**Compliance Prohibitions:**\n{{ JSON.stringify($json.context.prohibitions) }}\n\n---\n\nEvaluate ALL conversations according to the rubric criteria (1-5 scale each) and return the complete JSON evaluation.",
        "options": {
          "systemMessage": "=You are an AI-AS-JUDGE evaluation system.\n\nYour role is to objectively evaluate AI agent performance using a weighted rubric system.\n\n## EVALUATION RUBRIC (1-5 scale)\n\n{{ Object.entries($json.rubrica).map(([key, criteria]) => `### ${key.toUpperCase().replace('_', ' ')} (Weight: ${(criteria.weight * 100).toFixed(0)}%)\n**Question:** ${criteria.description}\n**Scale:**\n${Object.entries(criteria.scale).map(([score, desc]) => `- ${score}: ${desc}`).join('\\n')}\n${criteria.inverse ? '**Note:** This is inverse scoring - lower scores are better' : ''}`).join('\\n\\n') }}\n\n---\n\n## EVALUATION PROCESS\n\n1. **Read All Conversations Carefully**\n   - Analyze each conversation independently\n   - Look for patterns across conversations\n   - Consider context and user intent\n\n2. **Score Each Criterion (1-5)**\n   - Use the rubric scale definitions\n   - Provide evidence-based justification\n   - Be objective and consistent\n\n3. **Calculate Weighted Average**\n   - Multiply each score by its weight\n   - Sum all weighted scores\n   - Result: overall_score (0.0 - 5.0)\n\n4. **Generate Analysis**\n   - Identify strengths across conversations\n   - Identify weaknesses and patterns\n   - Detect recurring issues or exceptional behaviors\n\n## OUTPUT FORMAT (JSON)\n\n```json\n{\n  \"evaluation_id\": \"uuid\",\n  \"timestamp\": \"ISO 8601\",\n  \"agent\": {\n    \"id\": \"agent_id\",\n    \"name\": \"agent_name\",\n    \"client\": \"client_name\"\n  },\n  \"conversations_evaluated\": 0,\n  \"criteria_scores\": {\n    \"completeness\": {\n      \"score\": 1-5,\n      \"weight\": 0.20,\n      \"weighted_score\": 0.0-1.0,\n      \"justification\": \"explanation with examples\",\n      \"evidence\": [\"quote from conversation 1\", \"quote from conversation 2\"]\n    },\n    \"depth\": {\n      \"score\": 1-5,\n      \"weight\": 0.25,\n      \"weighted_score\": 0.0-1.25,\n      \"justification\": \"explanation with examples\",\n      \"evidence\": [\"examples\"]\n    },\n    \"tone\": {\n      \"score\": 1-5,\n      \"weight\": 0.15,\n      \"weighted_score\": 0.0-0.75,\n      \"justification\": \"explanation\",\n      \"evidence\": [\"examples\"]\n    },\n    \"scope\": {\n      \"score\": 1-5,\n      \"weight\": 0.20,\n      \"weighted_score\": 0.0-1.0,\n      \"justification\": \"explanation\",\n      \"evidence\": [\"examples\"]\n    },\n    \"missed_opportunities\": {\n      \"score\": 1-5,\n      \"weight\": 0.20,\n      \"weighted_score\": 0.0-1.0,\n      \"justification\": \"explanation (note: inverse scoring)\",\n      \"evidence\": [\"examples of missed opportunities\"],\n      \"inverse_scoring\": true\n    }\n  },\n  \"overall_score\": 0.0-5.0,\n  \"score_percentage\": 0-100,\n  \"rating\": \"EXCEPTIONAL|STRONG|SATISFACTORY|NEEDS_IMPROVEMENT|POOR\",\n  \"strengths\": [\n    {\n      \"category\": \"criterion or general\",\n      \"description\": \"what the agent did well\",\n      \"examples\": [\"specific quotes\"]\n    }\n  ],\n  \"weaknesses\": [\n    {\n      \"category\": \"criterion or general\",\n      \"description\": \"what needs improvement\",\n      \"examples\": [\"specific quotes\"],\n      \"severity\": \"HIGH|MEDIUM|LOW\"\n    }\n  ],\n  \"patterns\": {\n    \"positive\": [\"recurring good behaviors\"],\n    \"negative\": [\"recurring issues or mistakes\"]\n  },\n  \"recommendations\": [\n    {\n      \"area\": \"specific improvement area\",\n      \"suggestion\": \"actionable recommendation\",\n      \"impact\": \"HIGH|MEDIUM|LOW\",\n      \"priority\": \"IMMEDIATE|SHORT_TERM|LONG_TERM\"\n    }\n  ],\n  \"executive_summary\": \"2-3 sentence summary of overall performance\"\n}\n```\n\n## RATING SCALE\n\n- **EXCEPTIONAL** (4.5-5.0): Outstanding performance, exceeds expectations\n- **STRONG** (3.5-4.4): Good performance, minor areas for improvement\n- **SATISFACTORY** (2.5-3.4): Acceptable performance, several improvement opportunities\n- **NEEDS_IMPROVEMENT** (1.5-2.4): Below expectations, significant issues\n- **POOR** (0.0-1.4): Unacceptable performance, major problems\n\n## RULES\n\n1. **Be Objective**: Base all scores on evidence from conversations\n2. **Be Consistent**: Apply the same standards across all conversations\n3. **Be Specific**: Provide concrete examples and quotes\n4. **Be Fair**: Consider context and difficulty of user requests\n5. **Be Constructive**: Frame weaknesses as opportunities for improvement\n6. **Calculate Correctly**: Ensure weighted average is accurate\n7. **Return Valid JSON**: No markdown fences, just the JSON object"
        }
      },
      "type": "@n8n/n8n-nodes-langchain.chainLlm",
      "typeVersion": 1.4,
      "position": [1840, 100],
      "id": "ai-judge-evaluator",
      "name": "AI Judge - Evaluate with Rubric"
    },
    {
      "parameters": {
        "model": "llama-3.3-70b-versatile",
        "options": {
          "temperature": 0.2,
          "maxTokens": 4000
        }
      },
      "type": "@n8n/n8n-nodes-langchain.lmChatGroq",
      "typeVersion": 1,
      "position": [1912, 324],
      "id": "groq-llm",
      "name": "Groq LLM - Llama 3.3 70B",
      "credentials": {
        "groqApi": {
          "id": "WVbQ0d3w6cnLwPtX",
          "name": "Groq account"
        }
      }
    },
    {
      "parameters": {
        "jsCode": "// Parse e processar resultado da avaliacao AI-as-Judge\nconst evaluationContext = $('Prepare Evaluation Context + Rubric').first().json;\nconst aiResponse = $input.first().json;\n\n// Funcoes helper para parse\nfunction cleanJsonFences(str) {\n  if (typeof str !== 'string') str = String(str ?? '');\n  let result = str.trim();\n  result = result.replace(/^\\s*```[a-z]*\\s*/i, '');\n  result = result.replace(/\\s*```\\s*$/i, '');\n  return result;\n}\n\nfunction findJsonObject(str) {\n  const start = str.indexOf('{');\n  if (start === -1) return null;\n  \n  let depth = 0, inString = false, escaped = false;\n  for (let i = start; i < str.length; i++) {\n    const ch = str[i];\n    if (inString) {\n      if (escaped) escaped = false;\n      else if (ch === '\\\\') escaped = true;\n      else if (ch === '\"') inString = false;\n    } else {\n      if (ch === '\"') inString = true;\n      else if (ch === '{') depth++;\n      else if (ch === '}') {\n        depth--;\n        if (depth === 0) return str.slice(start, i + 1);\n      }\n    }\n  }\n  return null;\n}\n\nfunction tryParseJson(val) {\n  try { return JSON.parse(val); } catch {}\n  const cleaned = cleanJsonFences(val);\n  try { return JSON.parse(cleaned); } catch {}\n  const extracted = findJsonObject(cleaned);\n  if (extracted) {\n    try { return JSON.parse(extracted); } catch {}\n  }\n  return null;\n}\n\n// Parse resposta da AI\nconst rawOutput = aiResponse.text ?? aiResponse.response ?? aiResponse.output;\nconst outputString = typeof rawOutput === 'string' ? rawOutput : String(rawOutput ?? '');\nlet evaluation = typeof rawOutput === 'object' && rawOutput ? rawOutput : tryParseJson(outputString);\n\nif (!evaluation || !evaluation.criteria_scores) {\n  return [{\n    json: {\n      success: false,\n      error: 'Failed to parse evaluation JSON',\n      agent: evaluationContext.agent,\n      raw_output_preview: cleanJsonFences(outputString).substring(0, 500)\n    }\n  }];\n}\n\n// Extrair scores dos criterios\nconst criteriaScores = evaluation.criteria_scores || {};\nconst completeness = criteriaScores.completeness?.score || 0;\nconst depth = criteriaScores.depth?.score || 0;\nconst tone = criteriaScores.tone?.score || 0;\nconst scope = criteriaScores.scope?.score || 0;\nconst missedOpp = criteriaScores.missed_opportunities?.score || 0;\n\n// Calcular weighted average (se nao vier calculado)\nlet overallScore = evaluation.overall_score;\nif (!overallScore || overallScore === 0) {\n  const weights = evaluationContext.rubrica;\n  overallScore = (\n    (completeness * weights.completeness.weight) +\n    (depth * weights.depth.weight) +\n    (tone * weights.tone.weight) +\n    (scope * weights.scope.weight) +\n    (missedOpp * weights.missed_opportunities.weight)\n  );\n}\n\n// Calcular porcentagem\nconst scorePercentage = (overallScore / 5.0) * 100;\n\n// Determinar rating se nao vier\nlet rating = evaluation.rating;\nif (!rating) {\n  if (overallScore >= 4.5) rating = 'EXCEPTIONAL';\n  else if (overallScore >= 3.5) rating = 'STRONG';\n  else if (overallScore >= 2.5) rating = 'SATISFACTORY';\n  else if (overallScore >= 1.5) rating = 'NEEDS_IMPROVEMENT';\n  else rating = 'POOR';\n}\n\n// Identificar areas criticas\nconst criticalWeaknesses = (evaluation.weaknesses || []).filter(w => w.severity === 'HIGH');\nconst highPriorityRecommendations = (evaluation.recommendations || []).filter(r => r.priority === 'IMMEDIATE');\n\nreturn [{\n  json: {\n    success: true,\n    evaluation_id: evaluation.evaluation_id || `eval_${Date.now()}`,\n    timestamp: evaluation.timestamp || new Date().toISOString(),\n    agent: evaluationContext.agent,\n    conversations_evaluated: evaluationContext.total_conversations,\n    scores: {\n      completeness: completeness,\n      depth: depth,\n      tone: tone,\n      scope: scope,\n      missed_opportunities: missedOpp,\n      overall: parseFloat(overallScore.toFixed(2)),\n      percentage: parseFloat(scorePercentage.toFixed(1))\n    },\n    rating: rating,\n    criteria_details: criteriaScores,\n    strengths: evaluation.strengths || [],\n    weaknesses: evaluation.weaknesses || [],\n    patterns: evaluation.patterns || { positive: [], negative: [] },\n    recommendations: evaluation.recommendations || [],\n    summary: evaluation.executive_summary || 'Evaluation completed',\n    alerts: {\n      has_critical_weaknesses: criticalWeaknesses.length > 0,\n      critical_count: criticalWeaknesses.length,\n      has_urgent_recommendations: highPriorityRecommendations.length > 0,\n      needs_immediate_attention: overallScore < 2.5 || criticalWeaknesses.length > 0\n    },\n    full_evaluation: evaluation\n  }\n}];"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [2080, 100],
      "id": "parse-evaluation",
      "name": "Parse Scores & Calculate Metrics"
    },
    {
      "parameters": {
        "operation": "executeQuery",
        "query": "=INSERT INTO ai_judge_evaluations (\n  agent_version_id,\n  conversations_count,\n  score_completeness,\n  score_depth,\n  score_tone,\n  score_scope,\n  score_missed_opportunities,\n  overall_score,\n  score_percentage,\n  rating,\n  critical_weaknesses_count,\n  needs_attention,\n  evaluation_data,\n  summary,\n  created_at\n) VALUES (\n  '{{ $json.agent.id }}',\n  {{ $json.conversations_evaluated }},\n  {{ $json.scores.completeness }},\n  {{ $json.scores.depth }},\n  {{ $json.scores.tone }},\n  {{ $json.scores.scope }},\n  {{ $json.scores.missed_opportunities }},\n  {{ $json.scores.overall }},\n  {{ $json.scores.percentage }},\n  '{{ $json.rating }}',\n  {{ $json.alerts.critical_count }},\n  {{ $json.alerts.needs_immediate_attention }},\n  $1::jsonb,\n  '{{ ($json.summary || '').replace(/'/g, \"''\") }}',\n  NOW()\n)\nRETURNING id;",
        "options": {
          "queryParams": "={{ [JSON.stringify($json.full_evaluation)] }}"
        }
      },
      "type": "n8n-nodes-base.postgres",
      "typeVersion": 2.5,
      "position": [2320, 100],
      "id": "save-evaluation",
      "name": "Save Evaluation to Database",
      "credentials": {
        "postgres": {
          "id": "w2mBaRwhZ3tM4FUw",
          "name": "Postgres Marcos Daniels."
        }
      }
    },
    {
      "parameters": {
        "respondWith": "json",
        "responseBody": "={{ {\n  success: $json.success !== false,\n  evaluation_id: $('Parse Scores & Calculate Metrics').item.json.evaluation_id,\n  agent: $('Parse Scores & Calculate Metrics').item.json.agent,\n  scores: $('Parse Scores & Calculate Metrics').item.json.scores,\n  rating: $('Parse Scores & Calculate Metrics').item.json.rating,\n  summary: $('Parse Scores & Calculate Metrics').item.json.summary,\n  alerts: $('Parse Scores & Calculate Metrics').item.json.alerts,\n  strengths_count: $('Parse Scores & Calculate Metrics').item.json.strengths.length,\n  weaknesses_count: $('Parse Scores & Calculate Metrics').item.json.weaknesses.length,\n  recommendations_count: $('Parse Scores & Calculate Metrics').item.json.recommendations.length,\n  timestamp: $('Parse Scores & Calculate Metrics').item.json.timestamp\n} }}",
        "options": {}
      },
      "type": "n8n-nodes-base.respondToWebhook",
      "typeVersion": 1.1,
      "position": [2560, 100],
      "id": "respond-success",
      "name": "Respond - Success"
    },
    {
      "parameters": {
        "content": "## AI as Judge - Evaluation System\n\n**Function**: Evaluate agent performance using weighted rubric criteria.\n\n### Flow:\n1. **Webhook Trigger**: Receives agent_id + conversations array\n2. **Fetch Agent**: Get current system_prompt from Supabase\n3. **Prepare Rubric**: Build evaluation context with 5 criteria:\n   - Completeness (20%)\n   - Depth (25%)\n   - Tone (15%)\n   - Scope (20%)\n   - Missed Opportunities (20%)\n4. **AI Judge (Groq)**: Evaluates conversations on 1-5 scale\n5. **Parse Results**: Extract scores, calculate weighted average\n6. **Save to DB**: Store evaluation in ai_judge_evaluations\n7. **Return JSON**: Complete evaluation report\n\n### Rubric Criteria (1-5 scale):\n\n**Completeness (20%)**\n- Did the agent fully address the user's request?\n- 5 = Fully addressed all aspects\n- 1 = Completely missed the request\n\n**Depth (25%)**\n- Was the response thorough and insightful?\n- 5 = Exceptional depth with insights\n- 1 = Extremely shallow or generic\n\n**Tone (15%)**\n- Was the tone appropriate?\n- 5 = Perfect tone for context\n- 1 = Completely inappropriate\n\n**Scope (20%)**\n- Did the agent stay on topic?\n- 5 = Perfectly on-topic\n- 1 = Completely off-topic\n\n**Missed Opportunities (20%)**\n- Did the agent miss chances to help?\n- 5 = Seized all opportunities\n- 1 = Missed all opportunities\n\n### Rating Scale:\n- EXCEPTIONAL (4.5-5.0)\n- STRONG (3.5-4.4)\n- SATISFACTORY (2.5-3.4)\n- NEEDS_IMPROVEMENT (1.5-2.4)\n- POOR (0.0-1.4)\n\n### Output:\n- Individual criterion scores (1-5)\n- Weighted overall score (0-5)\n- Score percentage (0-100%)\n- Rating classification\n- Strengths & weaknesses\n- Patterns detected\n- Actionable recommendations",
        "height": 740,
        "width": 380,
        "color": 5
      },
      "type": "n8n-nodes-base.stickyNote",
      "typeVersion": 1,
      "position": [80, 100],
      "id": "sticky-instructions",
      "name": "Instructions"
    },
    {
      "parameters": {
        "content": "## Database Migration\n\n```sql\n-- Create ai_judge_evaluations table\nCREATE TABLE IF NOT EXISTS ai_judge_evaluations (\n  id UUID PRIMARY KEY DEFAULT gen_random_uuid(),\n  agent_version_id UUID NOT NULL,\n  conversations_count INTEGER DEFAULT 0,\n  score_completeness NUMERIC(3,2),\n  score_depth NUMERIC(3,2),\n  score_tone NUMERIC(3,2),\n  score_scope NUMERIC(3,2),\n  score_missed_opportunities NUMERIC(3,2),\n  overall_score NUMERIC(3,2),\n  score_percentage NUMERIC(5,2),\n  rating VARCHAR(50),\n  critical_weaknesses_count INTEGER DEFAULT 0,\n  needs_attention BOOLEAN DEFAULT FALSE,\n  evaluation_data JSONB,\n  summary TEXT,\n  created_at TIMESTAMP WITH TIME ZONE DEFAULT NOW(),\n  CONSTRAINT fk_agent_version\n    FOREIGN KEY (agent_version_id)\n    REFERENCES agent_versions(id)\n    ON DELETE CASCADE\n);\n\n-- Indexes\nCREATE INDEX IF NOT EXISTS idx_judge_eval_agent\nON ai_judge_evaluations(agent_version_id);\n\nCREATE INDEX IF NOT EXISTS idx_judge_eval_score\nON ai_judge_evaluations(overall_score DESC);\n\nCREATE INDEX IF NOT EXISTS idx_judge_eval_rating\nON ai_judge_evaluations(rating);\n\nCREATE INDEX IF NOT EXISTS idx_judge_eval_attention\nON ai_judge_evaluations(needs_attention, created_at DESC);\n\n-- Comments\nCOMMENT ON TABLE ai_judge_evaluations IS \n'AI-as-Judge evaluations using weighted rubric criteria';\n\nCOMMENT ON COLUMN ai_judge_evaluations.overall_score IS \n'Weighted average score (0.0-5.0)';\n\nCOMMENT ON COLUMN ai_judge_evaluations.score_percentage IS \n'Score as percentage (0-100%)';\n```\n\nRun this migration before activating!",
        "height": 600,
        "width": 380,
        "color": 6
      },
      "type": "n8n-nodes-base.stickyNote",
      "typeVersion": 1,
      "position": [80, 900],
      "id": "sticky-migration",
      "name": "Database Migration"
    },
    {
      "parameters": {
        "content": "## Usage Example\n\n**Webhook Endpoint:**\n```\nPOST /webhook/ai-as-judge-evaluate\n```\n\n**Request Body:**\n```json\n{\n  \"agent_id\": \"uuid-of-agent-version\",\n  \"conversations\": [\n    {\n      \"id\": \"conv_1\",\n      \"resultado\": \"agendado\",\n      \"messages\": [\n        {\n          \"is_from_lead\": true,\n          \"message_text\": \"Oi, preciso agendar\",\n          \"timestamp\": \"2025-12-27T10:00:00Z\"\n        },\n        {\n          \"is_from_lead\": false,\n          \"message_text\": \"Claro! Qual horario?\",\n          \"timestamp\": \"2025-12-27T10:01:00Z\"\n        }\n      ]\n    }\n  ],\n  \"evaluation_mode\": \"standard\"\n}\n```\n\n**Response:**\n```json\n{\n  \"success\": true,\n  \"evaluation_id\": \"eval_123\",\n  \"agent\": {\n    \"id\": \"agent_uuid\",\n    \"name\": \"Isabella SDR\"\n  },\n  \"scores\": {\n    \"completeness\": 4.5,\n    \"depth\": 4.0,\n    \"tone\": 5.0,\n    \"scope\": 4.5,\n    \"missed_opportunities\": 4.0,\n    \"overall\": 4.35,\n    \"percentage\": 87.0\n  },\n  \"rating\": \"STRONG\",\n  \"summary\": \"...\",\n  \"alerts\": {\n    \"has_critical_weaknesses\": false,\n    \"needs_immediate_attention\": false\n  }\n}\n```",
        "height": 680,
        "width": 380,
        "color": 4
      },
      "type": "n8n-nodes-base.stickyNote",
      "typeVersion": 1,
      "position": [480, 900],
      "id": "sticky-usage",
      "name": "Usage Example"
    }
  ],
  "connections": {
    "Webhook - Receive Evaluation Request": {
      "main": [
        [
          {
            "node": "Extract Request Payload",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Extract Request Payload": {
      "main": [
        [
          {
            "node": "Validate Input?",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Validate Input?": {
      "main": [
        [
          {
            "node": "Fetch Current Agent Prompt",
            "type": "main",
            "index": 0
          }
        ],
        [
          {
            "node": "Respond - Error",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Fetch Current Agent Prompt": {
      "main": [
        [
          {
            "node": "Agent Exists?",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Agent Exists?": {
      "main": [
        [
          {
            "node": "Prepare Evaluation Context + Rubric",
            "type": "main",
            "index": 0
          }
        ],
        [
          {
            "node": "Respond - Agent Not Found",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Prepare Evaluation Context + Rubric": {
      "main": [
        [
          {
            "node": "AI Judge - Evaluate with Rubric",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Groq LLM - Llama 3.3 70B": {
      "ai_languageModel": [
        [
          {
            "node": "AI Judge - Evaluate with Rubric",
            "type": "ai_languageModel",
            "index": 0
          }
        ]
      ]
    },
    "AI Judge - Evaluate with Rubric": {
      "main": [
        [
          {
            "node": "Parse Scores & Calculate Metrics",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Parse Scores & Calculate Metrics": {
      "main": [
        [
          {
            "node": "Save Evaluation to Database",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Save Evaluation to Database": {
      "main": [
        [
          {
            "node": "Respond - Success",
            "type": "main",
            "index": 0
          }
        ]
      ]
    }
  },
  "settings": {
    "executionOrder": "v1",
    "callerPolicy": "workflowsFromSameOwner",
    "availableInMCP": false,
    "timeSavedMode": "fixed"
  },
  "staticData": null,
  "meta": {
    "templateCredsSetupCompleted": true,
    "instanceId": "9d65e6caa0e89e696b77790e020391d74468b15f71b3dcdb63aad81f090f5e69"
  },
  "pinData": {},
  "versionId": "1.0.0",
  "triggerCount": 1,
  "tags": [
    {
      "name": "AI Factory",
      "createdAt": "2025-12-27T00:00:00.000Z",
      "updatedAt": "2025-12-27T00:00:00.000Z"
    },
    {
      "name": "Evaluation",
      "createdAt": "2025-12-27T00:00:00.000Z",
      "updatedAt": "2025-12-27T00:00:00.000Z"
    },
    {
      "name": "Self-Improving",
      "createdAt": "2025-12-27T00:00:00.000Z",
      "updatedAt": "2025-12-27T00:00:00.000Z"
    }
  ]
}
