{
  "name": "Prompt Updater",
  "nodes": [
    {
      "parameters": {
        "httpMethod": "POST",
        "path": "prompt-updater",
        "options": {}
      },
      "type": "n8n-nodes-base.webhook",
      "typeVersion": 1.1,
      "position": [
        -3632,
        2352
      ],
      "id": "3fc4e45d-05ba-46da-bc8a-0a75548d7a47",
      "name": "Webhook - Trigger Prompt Update",
      "webhookId": "prompt-updater"
    },
    {
      "parameters": {
        "assignments": {
          "assignments": [
            {
              "id": "agent-id",
              "name": "agent_id",
              "value": "={{ $json.body.agent_id }}",
              "type": "string"
            },
            {
              "id": "reflection-log-id",
              "name": "reflection_log_id",
              "value": "={{ $json.body.reflection_log_id }}",
              "type": "string"
            },
            {
              "id": "action-type",
              "name": "action_type",
              "value": "={{ $json.body.action_type || 'suggestion' }}",
              "type": "string"
            },
            {
              "id": "weaknesses",
              "name": "weaknesses",
              "value": "={{ $json.body.weaknesses }}",
              "type": "object"
            },
            {
              "id": "context",
              "name": "context",
              "value": "={{ $json.body.context || {} }}",
              "type": "object"
            }
          ]
        },
        "options": {}
      },
      "type": "n8n-nodes-base.set",
      "typeVersion": 3.4,
      "position": [
        -3392,
        2352
      ],
      "id": "71b557d4-eff1-4bea-b959-78bdfba1399e",
      "name": "Extract Webhook Data"
    },
    {
      "parameters": {
        "operation": "executeQuery",
        "query": "=SELECT \n  sp.id,\n  sp.agent_version_id,\n  sp.prompt_text,\n  sp.version_number,\n  sp.is_active,\n  sp.created_at,\n  av.agent_name,\n  av.compliance_rules,\n  av.personality_config,\n  av.business_config\nFROM system_prompts sp\nJOIN agent_versions av ON sp.agent_version_id = av.id\nWHERE av.id = '{{ $json.agent_id }}'\n  AND sp.is_active = true\nORDER BY sp.created_at DESC\nLIMIT 1",
        "options": {}
      },
      "type": "n8n-nodes-base.postgres",
      "typeVersion": 2.5,
      "position": [
        -3152,
        2352
      ],
      "id": "b86ba912-7ee8-418d-bdb0-4236415880da",
      "name": "Fetch Current Active Prompt",
      "credentials": {
        "postgres": {
          "id": "w2mBaRwhZ3tM4FUw",
          "name": "Postgres Marcos Daniels."
        }
      }
    },
    {
      "parameters": {
        "operation": "executeQuery",
        "query": "=SELECT \n  auto_apply_enabled,\n  min_confidence_threshold,\n  max_auto_updates_per_day,\n  require_human_approval,\n  enabled\nFROM self_improving_settings\nWHERE agent_version_id = '{{ $('Extract Webhook Data').item.json.agent_id }}'\nLIMIT 1",
        "options": {}
      },
      "type": "n8n-nodes-base.postgres",
      "typeVersion": 2.5,
      "position": [
        -2912,
        2352
      ],
      "id": "a2298484-edc1-4eac-bbe6-ff9fcc486614",
      "name": "Fetch Self-Improving Settings",
      "credentials": {
        "postgres": {
          "id": "w2mBaRwhZ3tM4FUw",
          "name": "Postgres Marcos Daniels."
        }
      }
    },
    {
      "parameters": {
        "conditions": {
          "options": {
            "caseSensitive": true,
            "leftValue": "",
            "typeValidation": "strict",
            "version": 2
          },
          "conditions": [
            {
              "id": "has-prompt",
              "leftValue": "={{ $json.id }}",
              "rightValue": "",
              "operator": {
                "type": "string",
                "operation": "exists",
                "singleValue": true
              }
            }
          ],
          "combinator": "and"
        },
        "options": {}
      },
      "type": "n8n-nodes-base.if",
      "typeVersion": 2.2,
      "position": [
        -2672,
        2352
      ],
      "id": "eefd8c18-1e68-452a-bd6d-37b14132abda",
      "name": "Prompt Exists?"
    },
    {
      "parameters": {},
      "type": "n8n-nodes-base.noOp",
      "typeVersion": 1,
      "position": [
        -2672,
        2560
      ],
      "id": "8b7cc3bf-4f5a-4c4e-9aa6-92dcb76f0c6f",
      "name": "Error - No Active Prompt"
    },
    {
      "parameters": {
        "jsCode": "// Prepare data for LLM improvement generation\nconst webhookData = $('Extract Webhook Data').first().json;\nconst currentPrompt = $('Fetch Current Active Prompt').first().json;\nconst settings = $('Fetch Self-Improving Settings').first().json;\n\n// Parse JSON fields\nfunction parseJson(val) {\n  if (typeof val === 'string') {\n    try { return JSON.parse(val); } catch { return {}; }\n  }\n  return val || {};\n}\n\nconst complianceRules = parseJson(currentPrompt.compliance_rules);\nconst personalityConfig = parseJson(currentPrompt.personality_config);\nconst businessConfig = parseJson(currentPrompt.business_config);\nconst weaknesses = webhookData.weaknesses || [];\nconst context = webhookData.context || {};\n\n// Build weakness summary\nconst weaknessSummary = weaknesses.map((w, idx) => {\n  return `${idx + 1}. **${w.dimensao}** (Nota: ${w.nota}/10)\\n   - Problema: ${w.problema}\\n   - Impacto: ${w.impacto}\\n   - Exemplos: ${(w.exemplos || []).join('; ')}`;\n}).join('\\n\\n');\n\n// Build context info\nconst contextInfo = [\n  `- Conversas analisadas: ${context.total_conversas || 'N/A'}`,\n  `- Media de notas: ${context.media_notas || 'N/A'}`,\n  `- Red flags recorrentes: ${(context.red_flags_recorrentes || []).join(', ') || 'Nenhum'}`,\n  `- Padroes identificados: ${context.padroes || 'N/A'}`\n].join('\\n');\n\nreturn [{\n  json: {\n    agent_id: webhookData.agent_id,\n    reflection_log_id: webhookData.reflection_log_id,\n    action_type: webhookData.action_type,\n    current_prompt: {\n      id: currentPrompt.id,\n      text: currentPrompt.prompt_text,\n      version: currentPrompt.version_number,\n      agent_name: currentPrompt.agent_name\n    },\n    settings: {\n      auto_apply_enabled: settings.auto_apply_enabled || false,\n      min_confidence: settings.min_confidence_threshold || 0.8,\n      max_daily_updates: settings.max_auto_updates_per_day || 3,\n      require_approval: settings.require_human_approval || true,\n      enabled: settings.enabled || false\n    },\n    weaknesses: weaknesses,\n    weakness_summary: weaknessSummary,\n    context_info: contextInfo,\n    compliance_rules: complianceRules,\n    personality_config: personalityConfig,\n    business_config: businessConfig\n  }\n}];"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        -2432,
        2240
      ],
      "id": "6cd7e311-4755-47b3-afe6-d8f1e61cc33f",
      "name": "Prepare LLM Input"
    },
    {
      "parameters": {
        "promptType": "define",
        "text": "=## DADOS PARA MELHORIA\n\n**Agente:** {{ $json.current_prompt.agent_name }}\n**Versão Atual:** {{ $json.current_prompt.version }}\n\n---\n\n## PROMPT ATUAL\n\n{{ $json.current_prompt.text }}\n\n---\n\n## FRAQUEZAS IDENTIFICADAS\n\n{{ $json.weakness_summary }}\n\n---\n\n## CONTEXTO DAS ANÁLISES\n\n{{ $json.context_info }}\n\n---\n\n## COMPLIANCE RULES\n\n{{ JSON.stringify($json.compliance_rules, null, 2) }}\n\n---\n\n## PERSONALIDADE ESPERADA\n\n{{ JSON.stringify($json.personality_config, null, 2) }}\n\n---\n\nGere a versão melhorada conforme instruções do system prompt.",
        "messages": {
          "messageValues": [
            {
              "message": "=# PROMPT IMPROVER AI - System Prompt\n\n> **Uso:** Copie o conteúdo abaixo (a partir de \"Você é o PROMPT IMPROVER AI\") e cole no campo \"System Message\" do nó AI no workflow 13-Prompt-Updater.\n\n---\n\nVocê é o **PROMPT IMPROVER AI** - um engenheiro de prompts especialista em otimização de agentes SDR conversacionais.\n\nSeu propósito é receber um prompt atual + análise de fraquezas e gerar uma versão MELHORADA que corrija os problemas identificados.\n\nVocê é:\n- **Conservador**: Mudanças cirúrgicas e focadas, não reescritas completas\n- **Preservador**: Mantém guardrails, compliance e estrutura original\n- **Preciso**: Foca APENAS nos problemas identificados\n- **Mensurável**: Cada mudança tem justificativa clara\n\n---\n\n## RESTRIÇÕES CRÍTICAS\n\n- A data de hoje é {{ $now }}\n- CRÍTICO: NUNCA remova guardrails de segurança, compliance ou regras de negócio\n- CRÍTICO: NUNCA altere a identidade/nome do agente sem instrução explícita\n- CRÍTICO: NUNCA invente informações sobre o negócio (preços, horários, serviços)\n- SEMPRE preserve a estrutura original do prompt (seções, ordem, formatação)\n- SEMPRE mantenha o tom/personalidade definidos no prompt original\n- Máximo de 5 mudanças significativas por iteração\n- Se o problema for de DADOS (ex: nome errado), NÃO corrija - sinalize como \"REQUER_CORRECAO_MANUAL\"\n- Confiança mínima de 0.7 para sugerir mudança\n- Output SEMPRE em JSON válido\n\n---\n\n## ESTRATÉGIAS DE MELHORIA\n\n### Para problemas de INSTRUÇÕES (fluxo, qualificação, agendamento):\n- Adicione ou refine passos específicos\n- Use exemplos concretos\n- Mantenha linguagem consistente\n\n### Para problemas de TOM/PERSONALIDADE:\n- Ajuste adjetivos e diretrizes de comunicação\n- Adicione exemplos de frases adequadas\n- NÃO mude a persona fundamental\n\n### Para problemas de QUALIFICAÇÃO:\n- Adicione perguntas específicas de descoberta\n- Inclua critérios claros (BANT, etc)\n- Defina ações para cada resultado\n\n### Para problemas de AGENDAMENTO:\n- Adicione protocolo passo-a-passo\n- Inclua templates de mensagem\n- Defina tratamento de objeções\n\n### Para problemas de DADOS DO NEGÓCIO:\n- NÃO corrija (você não tem autoridade)\n- Sinalize como \"REQUER_CORRECAO_MANUAL\"\n- Inclua na seção de alertas\n\n---\n\n## CÁLCULO DE CONFIANÇA\n\nCalcule confiança (0.0 a 1.0) baseado em:\n- Clareza do problema identificado (+0.2)\n- Solução bem definida (+0.2)\n- Baixo risco de efeitos colaterais (+0.2)\n- Mudança testável/mensurável (+0.2)\n- Alinhamento com melhores práticas (+0.2)\n\nSe confiança < 0.7, marque como \"REQUER_REVISAO_HUMANA\"\n\n---\n\n## FORMATO DE SAÍDA (JSON)\n\nRetorne SEMPRE um JSON válido com esta estrutura:\n\n```json\n{\n  \"metadata\": {\n    \"versao_anterior\": \"2.0\",\n    \"versao_nova\": \"2.1\",\n    \"timestamp\": \"2026-01-03T17:00:00Z\",\n    \"confianca_geral\": 0.85\n  },\n  \"analise_recebida\": {\n    \"score_original\": 6.5,\n    \"total_problemas\": 5,\n    \"problemas_enderecados\": 3,\n    \"problemas_ignorados\": 2,\n    \"razao_ignorados\": \"Baixa prioridade ou requer correção manual\"\n  },\n  \"mudancas_realizadas\": [\n    {\n      \"id\": 1,\n      \"tipo\": \"INSTRUCAO\",\n      \"secao_afetada\": \"Fluxo de Qualificação\",\n      \"problema_original\": \"Não qualifica adequadamente o lead\",\n      \"mudanca\": \"Adicionado checklist BANT obrigatório\",\n      \"justificativa\": \"Estrutura clara de qualificação aumenta conversão\",\n      \"confianca\": 0.85,\n      \"risco\": \"BAIXO\",\n      \"reversivel\": true\n    }\n  ],\n  \"alertas\": [\n    {\n      \"tipo\": \"REQUER_CORRECAO_MANUAL\",\n      \"descricao\": \"Nome do médico no prompt difere da operação real\",\n      \"acao_requerida\": \"Atualizar dados do negócio manualmente\"\n    }\n  ],\n  \"novo_prompt\": \"AQUI VAI O PROMPT COMPLETO MELHORADO - TODO O CONTEÚDO\",\n  \"diff_resumido\": {\n    \"linhas_adicionadas\": 15,\n    \"linhas_removidas\": 3,\n    \"linhas_modificadas\": 8,\n    \"secoes_alteradas\": [\"Qualificação\", \"Agendamento\"]\n  },\n  \"proximos_passos\": [\n    \"Monitorar conversas nas próximas 24h\",\n    \"Verificar se score melhora\",\n    \"Corrigir dados do negócio manualmente\"\n  ],\n  \"metricas_esperadas\": {\n    \"score_esperado\": 7.5,\n    \"melhoria_estimada\": \"+1.0\",\n    \"areas_impactadas\": [\"qualificacao\", \"agendamento\"]\n  }\n}\n```\n\n---\n\n## CASOS ESPECIAIS\n\n1. **Prompt mal estruturado**: Melhore E organize, mas marque como risco MÉDIO\n\n2. **Problemas contraditórios**: Priorize o de maior impacto (CRÍTICO > ALTO)\n\n3. **Dados incorretos**: NÃO corrija, adicione alerta \"REQUER_CORRECAO_MANUAL\"\n\n4. **Mudança complexa**: Divida em menores, sugira fases, marque \"REQUER_REVISAO_HUMANA\"\n\n5. **Score < 3.0**: Foque APENAS em problemas CRÍTICOS, máximo 3 mudanças\n\n6. **Histórico de regressão**: Não repita abordagem que piorou, sugira reversão\n\n---\n\n## REGRAS DO OUTPUT\n\n1. **novo_prompt** deve ser COMPLETO - não apenas as partes alteradas\n2. **confianca_geral** deve refletir a média das mudanças\n3. Se confianca_geral < 0.7, adicione alerta \"REQUER_REVISAO_HUMANA\"\n4. Nunca inclua texto fora do JSON\n5. Escape corretamente strings com aspas e quebras de linha\n\n---\n\n**IMPORTANTE**: Retorne APENAS o JSON válido, sem texto adicional ou markdown."
            }
          ]
        }
      },
      "type": "@n8n/n8n-nodes-langchain.chainLlm",
      "typeVersion": 1.4,
      "position": [
        -2192,
        2240
      ],
      "id": "c9e615e0-0e37-4c84-b095-e77f889c49e0",
      "name": "Generate Prompt Improvement"
    },
    {
      "parameters": {
        "model": "claude-opus-4-20250514",
        "options": {
          "maxTokensToSample": 8000,
          "temperature": 0.4
        }
      },
      "type": "@n8n/n8n-nodes-langchain.lmChatAnthropic",
      "typeVersion": 1.2,
      "position": [
        -2128,
        2480
      ],
      "id": "ac898748-a14a-4f69-8d85-1eb55fdbb63a",
      "name": "Claude Opus 4",
      "credentials": {
        "anthropicApi": {
          "id": "nNkFTZpNoiBCbO1I",
          "name": "Anthropic account"
        }
      }
    },
    {
      "parameters": {
        "jsCode": "// Process LLM response and extract improvement data\nconst preparedData = $('Prepare LLM Input').first().json;\nconst llmResponse = $input.first().json;\n\n// JSON parsing utilities\nfunction cleanFences(s) {\n  if (typeof s !== 'string') s = String(s ?? '');\n  let r = s.trim();\n  r = r.replace(/^\\s*```[a-z]*\\s*/i, '');\n  r = r.replace(/\\s*```$/, '');\n  return r;\n}\n\nfunction findBalancedEnd(s, start) {\n  let depth = 0, inStr = false, esc = false;\n  for (let i = start; i < s.length; i++) {\n    const ch = s[i];\n    if (inStr) {\n      if (esc) { esc = false; }\n      else if (ch === '\\\\') { esc = true; }\n      else if (ch === '\"') { inStr = false; }\n    } else {\n      if (ch === '\"') inStr = true;\n      else if (ch === '{') depth++;\n      else if (ch === '}') { depth--; if (depth === 0) return i; }\n    }\n  }\n  return -1;\n}\n\nfunction tryParse(str) {\n  try { return JSON.parse(str); } catch {}\n  const raw = cleanFences(str);\n  try { return JSON.parse(raw); } catch {}\n  const start = raw.indexOf('{');\n  const end = start >= 0 ? findBalancedEnd(raw, start) : -1;\n  if (start >= 0 && end >= 0) {\n    const jsonStr = raw.slice(start, end + 1);\n    try { return JSON.parse(jsonStr); } catch {}\n  }\n  return null;\n}\n\n// Parse LLM response\nlet improvement;\nconst rawVal = llmResponse.text ?? llmResponse.response ?? llmResponse.output;\nconst outputStr = typeof rawVal === 'string' ? rawVal : String(rawVal ?? '');\nimprovement = typeof rawVal === 'object' && rawVal ? rawVal : tryParse(outputStr);\n\nif (!improvement || !improvement.improved_prompt) {\n  return [{\n    json: {\n      error: true,\n      message: 'Failed to parse LLM improvement response',\n      raw_snippet: cleanFences(outputStr).slice(0, 500),\n      agent_id: preparedData.agent_id\n    }\n  }];\n}\n\nconst confidenceScore = parseFloat(improvement.confidence_score) || 0.0;\nconst actionType = preparedData.action_type;\nconst settings = preparedData.settings;\n\n// Determine if should auto-apply\nconst shouldAutoApply = \n  actionType === 'auto_update' && \n  settings.auto_apply_enabled === true &&\n  settings.enabled === true &&\n  confidenceScore >= settings.min_confidence &&\n  settings.require_approval === false;\n\nreturn [{\n  json: {\n    agent_id: preparedData.agent_id,\n    reflection_log_id: preparedData.reflection_log_id,\n    current_prompt_id: preparedData.current_prompt.id,\n    current_version: preparedData.current_prompt.version,\n    improved_prompt: improvement.improved_prompt,\n    confidence_score: confidenceScore,\n    confidence_reasoning: improvement.confidence_reasoning || '',\n    changes_made: improvement.changes_made || [],\n    expected_improvements: improvement.expected_improvements || [],\n    risks: improvement.risks || [],\n    testing_suggestions: improvement.testing_suggestions || [],\n    should_auto_apply: shouldAutoApply,\n    action_type: actionType,\n    settings: settings,\n    weaknesses_addressed: preparedData.weaknesses.map(w => w.dimensao).join(', ')\n  }\n}];"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        -1952,
        2240
      ],
      "id": "21ce7df8-ac5e-4cb7-957e-0a7fc00c5132",
      "name": "Process LLM Response"
    },
    {
      "parameters": {
        "rules": {
          "values": [
            {
              "conditions": {
                "options": {
                  "caseSensitive": true,
                  "leftValue": "",
                  "typeValidation": "strict"
                },
                "conditions": [
                  {
                    "leftValue": "={{ $json.should_auto_apply }}",
                    "rightValue": true,
                    "operator": {
                      "type": "boolean",
                      "operation": "equals"
                    }
                  }
                ],
                "combinator": "and"
              },
              "renameOutput": true,
              "outputKey": "auto_apply"
            },
            {
              "conditions": {
                "options": {
                  "caseSensitive": true,
                  "leftValue": "",
                  "typeValidation": "strict"
                },
                "conditions": [
                  {
                    "leftValue": "={{ $json.should_auto_apply }}",
                    "rightValue": false,
                    "operator": {
                      "type": "boolean",
                      "operation": "equals"
                    }
                  }
                ],
                "combinator": "and"
              },
              "renameOutput": true,
              "outputKey": "suggestion"
            }
          ]
        },
        "options": {}
      },
      "type": "n8n-nodes-base.switch",
      "typeVersion": 3,
      "position": [
        -1712,
        2240
      ],
      "id": "00d6c3c8-1dce-4ac6-b897-99ab6c793411",
      "name": "Switch - Auto Apply or Suggestion"
    },
    {
      "parameters": {
        "operation": "executeQuery",
        "query": "=-- Create new prompt version\nINSERT INTO system_prompts (\n  agent_version_id,\n  prompt_text,\n  version_number,\n  is_active,\n  created_by,\n  change_reason,\n  metadata\n) VALUES (\n  '{{ $json.agent_id }}',\n  $1::text,\n  {{ $json.current_version + 1 }},\n  false,\n  'prompt_updater_ai',\n  'Auto-applied improvement based on QA analysis',\n  $2::jsonb\n)\nRETURNING id, version_number;",
        "options": {}
      },
      "type": "n8n-nodes-base.postgres",
      "typeVersion": 2.5,
      "position": [
        -1472,
        2128
      ],
      "id": "dfe709e6-0152-4dc6-ad6c-8a362fd74a61",
      "name": "Create New Prompt Version",
      "credentials": {
        "postgres": {
          "id": "w2mBaRwhZ3tM4FUw",
          "name": "Postgres Marcos Daniels."
        }
      }
    },
    {
      "parameters": {
        "operation": "executeQuery",
        "query": "=-- Deactivate old prompts (trigger will handle single_active)\nUPDATE system_prompts\nSET is_active = false\nWHERE agent_version_id = '{{ $('Process LLM Response').item.json.agent_id }}'\n  AND is_active = true\n  AND id != '{{ $json.id }}';",
        "options": {}
      },
      "type": "n8n-nodes-base.postgres",
      "typeVersion": 2.5,
      "position": [
        -1232,
        2128
      ],
      "id": "0f2b34ed-10e5-4a07-bbec-b6c64d983630",
      "name": "Deactivate Old Prompts",
      "credentials": {
        "postgres": {
          "id": "w2mBaRwhZ3tM4FUw",
          "name": "Postgres Marcos Daniels."
        }
      }
    },
    {
      "parameters": {
        "operation": "executeQuery",
        "query": "=-- Activate new prompt\nUPDATE system_prompts\nSET is_active = true\nWHERE id = '{{ $('Create New Prompt Version').item.json.id }}';",
        "options": {}
      },
      "type": "n8n-nodes-base.postgres",
      "typeVersion": 2.5,
      "position": [
        -992,
        2128
      ],
      "id": "0e160675-5240-4f3f-a188-c0539577fd37",
      "name": "Activate New Prompt",
      "credentials": {
        "postgres": {
          "id": "w2mBaRwhZ3tM4FUw",
          "name": "Postgres Marcos Daniels."
        }
      }
    },
    {
      "parameters": {
        "operation": "executeQuery",
        "query": "=-- Update improvement_suggestions with auto-applied status\nUPDATE improvement_suggestions\nSET \n  status = 'auto_applied',\n  applied_at = NOW(),\n  applied_prompt_version = {{ $('Create New Prompt Version').item.json.version_number }}\nWHERE reflection_log_id = '{{ $('Process LLM Response').item.json.reflection_log_id }}';",
        "options": {}
      },
      "type": "n8n-nodes-base.postgres",
      "typeVersion": 2.5,
      "position": [
        -752,
        2128
      ],
      "id": "d9b8f8bd-6b92-4ff3-bcba-50991d78c56e",
      "name": "Mark Suggestion as Auto-Applied",
      "credentials": {
        "postgres": {
          "id": "w2mBaRwhZ3tM4FUw",
          "name": "Postgres Marcos Daniels."
        }
      }
    },
    {
      "parameters": {
        "operation": "executeQuery",
        "query": "=-- Save as pending suggestion\nINSERT INTO improvement_suggestions (\n  agent_version_id,\n  reflection_log_id,\n  suggestion_type,\n  current_prompt_version,\n  proposed_prompt,\n  confidence_score,\n  changes_summary,\n  expected_impact,\n  risks,\n  status,\n  metadata\n) VALUES (\n  '{{ $json.agent_id }}',\n  '{{ $json.reflection_log_id }}',\n  'prompt_improvement',\n  {{ $json.current_version }},\n  $1::text,\n  {{ $json.confidence_score }},\n  $2::jsonb,\n  $3::jsonb,\n  $4::jsonb,\n  'pending',\n  $5::jsonb\n)\nRETURNING id;",
        "options": {}
      },
      "type": "n8n-nodes-base.postgres",
      "typeVersion": 2.5,
      "position": [
        -1472,
        2368
      ],
      "id": "b07aadab-dc3e-4d0f-b7a8-1a88ea539461",
      "name": "Save as Pending Suggestion",
      "credentials": {
        "postgres": {
          "id": "w2mBaRwhZ3tM4FUw",
          "name": "Postgres Marcos Daniels."
        }
      }
    },
    {
      "parameters": {
        "method": "POST",
        "url": "={{ $('Process LLM Response').item.json.settings.notification_webhook_url || 'https://webhook.site/test' }}",
        "sendBody": true,
        "specifyBody": "json",
        "jsonBody": "={\n  \"event\": \"prompt_auto_applied\",\n  \"agent_id\": \"{{ $('Process LLM Response').item.json.agent_id }}\",\n  \"new_version\": {{ $json.version_number }},\n  \"confidence_score\": {{ $('Process LLM Response').item.json.confidence_score }},\n  \"changes_count\": {{ $('Process LLM Response').item.json.changes_made.length }},\n  \"expected_improvements\": {{ JSON.stringify($('Process LLM Response').item.json.expected_improvements) }},\n  \"timestamp\": \"{{ $now.toISO() }}\"\n}",
        "options": {}
      },
      "type": "n8n-nodes-base.httpRequest",
      "typeVersion": 4.2,
      "position": [
        -512,
        2128
      ],
      "id": "132c6599-93f2-4549-9d8b-a39ce0f1dbc6",
      "name": "Notify - Auto Applied"
    },
    {
      "parameters": {
        "method": "POST",
        "url": "={{ $('Process LLM Response').item.json.settings.notification_webhook_url || 'https://webhook.site/test' }}",
        "sendBody": true,
        "specifyBody": "json",
        "jsonBody": "={\n  \"event\": \"prompt_suggestion_created\",\n  \"agent_id\": \"{{ $('Process LLM Response').item.json.agent_id }}\",\n  \"suggestion_id\": \"{{ $json.id }}\",\n  \"confidence_score\": {{ $('Process LLM Response').item.json.confidence_score }},\n  \"reason\": \"{{ $('Process LLM Response').item.json.should_auto_apply === false ? 'Confidence below threshold or auto-apply disabled' : 'Manual review requested' }}\",\n  \"changes_count\": {{ $('Process LLM Response').item.json.changes_made.length }},\n  \"timestamp\": \"{{ $now.toISO() }}\"\n}",
        "options": {}
      },
      "type": "n8n-nodes-base.httpRequest",
      "typeVersion": 4.2,
      "position": [
        -1232,
        2368
      ],
      "id": "ed8db3bf-668d-4a0c-bfb8-7b896d8f1e2a",
      "name": "Notify - Suggestion Created"
    },
    {
      "parameters": {
        "content": "## Prompt Updater v1.0 (CAMADA 4 - SELF-IMPROVING)\n\n**Funcao**: Gerar e aplicar melhorias nos prompts dos agentes baseado em analises QA.\n\n### Fluxo:\n1. **Webhook** recebe trigger com:\n   - agent_id\n   - reflection_log_id\n   - action_type (suggestion | auto_update)\n   - weaknesses (array de problemas)\n   - context (dados agregados)\n\n2. **Fetch Data**:\n   - Prompt ativo atual\n   - Settings de self-improving\n\n3. **Generate Improvement**:\n   - Claude Opus 4 analisa fraquezas\n   - Gera prompt melhorado\n   - Calcula confidence score\n\n4. **Decision**:\n   - **Auto-Apply** SE:\n     * action=auto_update\n     * confidence >= threshold\n     * auto_apply_enabled=true\n     * require_approval=false\n   - **Suggestion** caso contrario\n\n5. **Execute**:\n   - Auto: Cria versao, ativa, notifica\n   - Suggestion: Salva pending, notifica\n\n### Confidence Thresholds:\n- 0.9-1.0: Mudanca simples, baixo risco\n- 0.7-0.89: Mudanca moderada\n- 0.5-0.69: Requer validacao\n- < 0.5: Experimental",
        "height": 620,
        "width": 380,
        "color": 5
      },
      "type": "n8n-nodes-base.stickyNote",
      "typeVersion": 1,
      "position": [
        -3952,
        2144
      ],
      "id": "b654d1f6-f540-4b73-89f7-fe10116122d6",
      "name": "Instructions"
    },
    {
      "parameters": {
        "content": "## Database Tables Required\n\n```sql\n-- improvement_suggestions\nCREATE TABLE IF NOT EXISTS improvement_suggestions (\n  id UUID PRIMARY KEY DEFAULT gen_random_uuid(),\n  agent_version_id UUID NOT NULL,\n  reflection_log_id UUID,\n  suggestion_type VARCHAR(50),\n  current_prompt_version INTEGER,\n  proposed_prompt TEXT,\n  confidence_score NUMERIC(3,2),\n  changes_summary JSONB,\n  expected_impact JSONB,\n  risks JSONB,\n  status VARCHAR(30) DEFAULT 'pending',\n  applied_at TIMESTAMP,\n  applied_prompt_version INTEGER,\n  metadata JSONB,\n  created_at TIMESTAMP DEFAULT NOW()\n);\n\n-- self_improving_settings\nCREATE TABLE IF NOT EXISTS self_improving_settings (\n  id UUID PRIMARY KEY DEFAULT gen_random_uuid(),\n  agent_version_id UUID UNIQUE NOT NULL,\n  enabled BOOLEAN DEFAULT false,\n  auto_apply_enabled BOOLEAN DEFAULT false,\n  min_confidence_threshold NUMERIC(3,2) DEFAULT 0.8,\n  max_auto_updates_per_day INTEGER DEFAULT 3,\n  require_human_approval BOOLEAN DEFAULT true,\n  notification_webhook_url TEXT,\n  created_at TIMESTAMP DEFAULT NOW(),\n  updated_at TIMESTAMP DEFAULT NOW()\n);\n```",
        "height": 560,
        "width": 380,
        "color": 6
      },
      "type": "n8n-nodes-base.stickyNote",
      "typeVersion": 1,
      "position": [
        -3952,
        2800
      ],
      "id": "093fd2bb-9d9a-4e13-b43d-c33ee98152fa",
      "name": "Database Schema"
    },
    {
      "parameters": {
        "content": "## Webhook Payload Example\n\n```json\n{\n  \"agent_id\": \"uuid\",\n  \"reflection_log_id\": \"uuid\",\n  \"action_type\": \"auto_update\",\n  \"weaknesses\": [\n    {\n      \"dimensao\": \"clareza_conducao\",\n      \"nota\": 6.5,\n      \"problema\": \"Lead confuso sobre proximos passos\",\n      \"impacto\": \"ALTO\",\n      \"exemplos\": [\n        \"Lead perguntou 3x o que fazer\"\n      ]\n    }\n  ],\n  \"context\": {\n    \"total_conversas\": 15,\n    \"media_notas\": 7.2,\n    \"red_flags_recorrentes\": [\n      \"loop_perguntas\"\n    ],\n    \"padroes\": \"Agente repete instrucoes\"\n  }\n}\n```\n\n### action_type:\n- **suggestion**: Sempre salva como pending\n- **auto_update**: Aplica se criterios atendidos",
        "height": 520,
        "width": 340,
        "color": 7
      },
      "type": "n8n-nodes-base.stickyNote",
      "typeVersion": 1,
      "position": [
        -3552,
        2800
      ],
      "id": "8c4da85f-833c-4890-85f9-25480606b565",
      "name": "Webhook Payload"
    },
    {
      "parameters": {
        "model": "llama-3.3-70b-versatile",
        "options": {}
      },
      "type": "@n8n/n8n-nodes-langchain.lmChatGroq",
      "typeVersion": 1,
      "position": [
        -2240,
        2496
      ],
      "id": "87365157-3993-4522-9e18-8b1191755c20",
      "name": "Groq Chat Model",
      "credentials": {
        "groqApi": {
          "id": "WVbQ0d3w6cnLwPtX",
          "name": "Groq account"
        }
      }
    }
  ],
  "pinData": {},
  "connections": {
    "Webhook - Trigger Prompt Update": {
      "main": [
        [
          {
            "node": "Extract Webhook Data",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Extract Webhook Data": {
      "main": [
        [
          {
            "node": "Fetch Current Active Prompt",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Fetch Current Active Prompt": {
      "main": [
        [
          {
            "node": "Fetch Self-Improving Settings",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Fetch Self-Improving Settings": {
      "main": [
        [
          {
            "node": "Prompt Exists?",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Prompt Exists?": {
      "main": [
        [
          {
            "node": "Prepare LLM Input",
            "type": "main",
            "index": 0
          }
        ],
        [
          {
            "node": "Error - No Active Prompt",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Prepare LLM Input": {
      "main": [
        [
          {
            "node": "Generate Prompt Improvement",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Generate Prompt Improvement": {
      "main": [
        [
          {
            "node": "Process LLM Response",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Process LLM Response": {
      "main": [
        [
          {
            "node": "Switch - Auto Apply or Suggestion",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Switch - Auto Apply or Suggestion": {
      "main": [
        [
          {
            "node": "Create New Prompt Version",
            "type": "main",
            "index": 0
          }
        ],
        [
          {
            "node": "Save as Pending Suggestion",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Create New Prompt Version": {
      "main": [
        [
          {
            "node": "Deactivate Old Prompts",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Deactivate Old Prompts": {
      "main": [
        [
          {
            "node": "Activate New Prompt",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Activate New Prompt": {
      "main": [
        [
          {
            "node": "Mark Suggestion as Auto-Applied",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Mark Suggestion as Auto-Applied": {
      "main": [
        [
          {
            "node": "Notify - Auto Applied",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Save as Pending Suggestion": {
      "main": [
        [
          {
            "node": "Notify - Suggestion Created",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Groq Chat Model": {
      "ai_languageModel": [
        [
          {
            "node": "Generate Prompt Improvement",
            "type": "ai_languageModel",
            "index": 0
          }
        ]
      ]
    }
  },
  "active": true,
  "settings": {
    "executionOrder": "v1"
  },
  "versionId": "dabb0f5c-4eb6-4fb6-b794-fff318be71f3",
  "meta": {
    "templateCredsSetupCompleted": true,
    "instanceId": "9d65e6caa0e89e696b77790e020391d74468b15f71b3dcdb63aad81f090f5e69"
  },
  "id": "Tl8KW0FKq1TeYsMt",
  "tags": []
}