#!/usr/bin/env python3
"""
Run AI Sales Simulation
========================
Executa simulaÃ§Ã£o de conversas com debate de especialistas.

Uso:
    python run_simulation.py                    # SimulaÃ§Ã£o padrÃ£o (3 personas)
    python run_simulation.py --quick            # SimulaÃ§Ã£o rÃ¡pida (1 persona)
    python run_simulation.py --full             # SimulaÃ§Ã£o completa (5 personas)
    python run_simulation.py --persona maria_preco  # Persona especÃ­fica
"""

import os
import sys
import asyncio
import argparse

# Setup path
sys.path.insert(0, os.path.dirname(os.path.abspath(__file__)))

# Configurar variÃ¡veis
os.environ.setdefault('GROQ_API_KEY', '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')
os.environ.setdefault('SUPABASE_SERVICE_KEY', 'eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJzdXBhYmFzZSIsInJlZiI6ImJmdW15d3Z3dWJ2ZXJudmhqZWhrIiwicm9sZSI6InNlcnZpY2Vfcm9sZSIsImlhdCI6MTc1MTQwMzc5OSwiZXhwIjoyMDY2OTc5Nzk5fQ.fdTsdGlSqemXzrXEU4ov1SUpeDn_3bSjOingqkSAWQE')

from simulator.orchestrator import SimulationOrchestrator
from simulator.lead_simulator import LEAD_PERSONAS


def print_header():
    print("""
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘                    ğŸ­ AI SALES SIMULATOR                          â•‘
â•‘                    Debate Multi-LLM Engine                        â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
""")


async def main():
    parser = argparse.ArgumentParser(description='AI Sales Simulation')
    parser.add_argument('--quick', action='store_true', help='SimulaÃ§Ã£o rÃ¡pida (1 persona)')
    parser.add_argument('--full', action='store_true', help='SimulaÃ§Ã£o completa (todas personas)')
    parser.add_argument('--persona', type=str, help='Persona especÃ­fica')
    parser.add_argument('--no-analyze', action='store_true', help='Pular anÃ¡lise de especialistas')
    parser.add_argument('--list-personas', action='store_true', help='Listar personas disponÃ­veis')

    args = parser.parse_args()

    print_header()

    # Listar personas
    if args.list_personas:
        print("ğŸ“‹ PERSONAS DISPONÃVEIS:\n")
        for name, persona in LEAD_PERSONAS.items():
            print(f"  â€¢ {name}")
            print(f"    Tipo: {persona.lead_type.value}")
            print(f"    Sintoma: {persona.symptom}")
            print(f"    ObjeÃ§Ãµes: {', '.join(persona.objections[:2])}...")
            print()
        return

    # Definir personas
    if args.persona:
        if args.persona not in LEAD_PERSONAS:
            print(f"âŒ Persona '{args.persona}' nÃ£o encontrada!")
            print(f"   Use --list-personas para ver disponÃ­veis")
            return
        personas = [args.persona]
    elif args.quick:
        personas = ["maria_preco"]
    elif args.full:
        personas = list(LEAD_PERSONAS.keys())
    else:
        personas = ["maria_preco", "claudia_emocional", "patricia_pronta"]

    print(f"ğŸ¯ Personas selecionadas: {', '.join(personas)}")
    print(f"ğŸ“Š AnÃ¡lise de especialistas: {'NÃ£o' if args.no_analyze else 'Sim'}")
    print()

    # Executar simulaÃ§Ã£o
    orchestrator = SimulationOrchestrator()

    try:
        report = await orchestrator.run_full_simulation(
            personas=personas,
            analyze=not args.no_analyze
        )

        orchestrator.print_report(report)

        # Salvar relatÃ³rio
        import json
        from datetime import datetime

        report_data = {
            "timestamp": report.timestamp,
            "prompt_version": report.prompt_version,
            "overall_score": report.overall_score,
            "needs_improvement": report.needs_improvement,
            "simulations": [
                {
                    "persona": s.persona_name,
                    "outcome": s.outcome,
                    "turn_count": s.turn_count,
                    "score": s.debate_result.average_score if s.debate_result else None
                }
                for s in report.simulations
            ],
            "recommended_changes": report.recommended_changes[:5]
        }

        report_file = f"simulation_report_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
        with open(report_file, 'w') as f:
            json.dump(report_data, f, indent=2, ensure_ascii=False)

        print(f"\nğŸ’¾ RelatÃ³rio salvo: {report_file}")

        # Retorna cÃ³digo de saÃ­da baseado no score
        if report.needs_improvement:
            print(f"\nâš ï¸  Score abaixo do mÃ­nimo (75). Melhorias recomendadas!")
            return 1
        else:
            print(f"\nâœ… Score satisfatÃ³rio!")
            return 0

    except Exception as e:
        print(f"\nâŒ Erro na simulaÃ§Ã£o: {e}")
        import traceback
        traceback.print_exc()
        return 2


if __name__ == '__main__':
    exit_code = asyncio.run(main())
    sys.exit(exit_code)
